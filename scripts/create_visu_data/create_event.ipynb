{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import utils\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_path = ['../../data/clean_data/events_2015_2018_filtered.csv', '../../data/clean_data/incidents.csv']\n",
    "events_name = ['events', 'incidents']\n",
    "json_path = '../../dashboards/data/json/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:29<00:00, 12.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for ep, file_name in tqdm(zip(events_path, events_name),\n",
    "                          total=len(events_path)):\n",
    "\n",
    "    events = pd.read_csv(ep).fillna('null')\n",
    "    d = {}\n",
    "\n",
    "    #list event per timestep\n",
    "    df_ = events.set_index(['stop_id', 'start_datetime']).copy()\n",
    "    for si, sd in df_.reset_index().drop_duplicates(['stop_id', 'start_datetime'])[['stop_id', 'start_datetime']].values:\n",
    "        try:\n",
    "            d[str(si)][sd]['list_event'] = df_.loc[si].loc[[sd]].to_dict(orient='records')\n",
    "        except:\n",
    "            try:\n",
    "                d[str(si)][sd] = {}\n",
    "                d[str(si)][sd]['list_event'] = df_.loc[si].loc[[sd]].to_dict(orient='records')\n",
    "            except:\n",
    "                d[str(si)] = {}\n",
    "                d[str(si)][sd] = {}\n",
    "                d[str(si)][sd]['list_event'] = df_.loc[si].loc[[sd]].to_dict(orient='records')\n",
    "                \n",
    "    # list event per day\n",
    "    df_ = events.copy()\n",
    "    df_['datetime'] = [i[:10] for i in df_['start_datetime'].values]\n",
    "    df_ = df_.set_index(['stop_id', 'datetime'])\n",
    "    for si, sd in df_.reset_index().drop_duplicates(['stop_id','datetime'])[['stop_id', 'datetime']].values:\n",
    "\n",
    "        try:\n",
    "            d[str(si)][sd]['list_event'] = df_.loc[si].loc[[sd]].to_dict(orient='records')\n",
    "        except:\n",
    "            try:\n",
    "                d[str(si)][sd] = {}\n",
    "                d[str(si)][sd]['list_event'] = df_.loc[si].loc[[sd]].to_dict(orient='records')\n",
    "            except:\n",
    "                d[str(si)] = {}\n",
    "                d[str(si)][sd] = {}\n",
    "                d[str(si)][sd]['list_event'] = df_.loc[si].loc[[sd]].to_dict(orient='records')\n",
    "\n",
    "    #Save\n",
    "    with open(json_path+file_name+'.json', 'w') as fp:\n",
    "        json.dump(d, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
